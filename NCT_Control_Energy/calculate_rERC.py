import argparse
import os
import numpy as np
import pandas as pd
import scipy.io as sio

def calculate_rerc_for_subject(sub_id, mat_path, initial_aveTE):
    """
    Computes rERC vector (210,) for a single subject.
    rERC = (aveTE_0 - aveTE_k) / aveTE_0
    """
    if not os.path.exists(mat_path):
        print(f"Warning: File not found {mat_path}")
        return None

    # Load MAT file: 'oce' is shape (210, 7, 7)
    energy_mat = sio.loadmat(mat_path)
    oce_changed = energy_mat['oce']
    
    # Reshape to (210, 49)
    n_roi = oce_changed.shape[0]
    n_transitions_total = oce_changed.shape[1] * oce_changed.shape[2]
    oce_changed_flat = oce_changed.reshape(n_roi, n_transitions_total)
    
    # Exclude diagonal elements (Self-transitions) for 7x7 matrix
    # Diagonals are at indices: 0, 8, 16, 24, 32, 40, 48
    diag_indices = [0, 8, 16, 24, 32, 40, 48]
    off_diag_indices = [i for i in range(49) if i not in diag_indices]
    
    # Keep only off-diagonal transitions (42 columns)
    oce_changed_42 = oce_changed_flat[:, off_diag_indices]
    
    # Compute aveTE_k (mean across 42 transitions for each ROI) -> (210,)
    aveTE_k = oce_changed_42.mean(axis=1)
    
    # Compute rERC
    # delta_aveTE = initial_aveTE - aveTE_k
    # rERC = delta_aveTE / initial_aveTE
    rerc_vector = (initial_aveTE - aveTE_k) / initial_aveTE
    
    return rerc_vector

def main(root_dir, add1_dir, baseline_csv_dir, list_dir, output_dir):
    
    n_ROI = 210
    
    # Load Subject Lists
    mdd_path = os.path.join(list_dir, 'MDD_list.txt')
    hc_path = os.path.join(list_dir, 'HC_list.txt')
    
    if not os.path.exists(mdd_path) or not os.path.exists(hc_path):
        print("Error: Subject list files not found.")
        return

    mdd_list = np.loadtxt(mdd_path).astype(int)
    hc_list = np.loadtxt(hc_path).astype(int)
    
    # Combine lists: MDD then HC
    id_list = np.concatenate((mdd_list, hc_list))
    
    # Prepare Subject and Condition columns for the final long-format DataFrame
    # Total rows = (Num_MDD + Num_HC) * n_ROI
    mdd_num = len(mdd_list)
    hc_num = len(hc_list)
    
    # Create repeated ID array
    subid_extended = np.repeat(id_list, n_ROI)
    
    # Create condition array
    condition_list = np.concatenate([
        np.repeat(['MDD'], mdd_num * n_ROI),
        np.repeat(['HC'], hc_num * n_ROI)
    ])
    
    # Create ROI label array (ROI_1 to ROI_210) repeated for each subject
    roi_labels = [f'ROI_{i}' for i in range(1, n_ROI + 1)]
    states_list = np.tile(roi_labels, len(id_list))

    # Loop through analysis parameters
    # Modify these lists based on what you actually ran
    thresholds = ['thr_0', 'nonthr']
    T_values = [1, 3]
    
    os.makedirs(output_dir, exist_ok=True)

    for thre_type in thresholds:
        for T_value in T_values:
            print(f"\nProcessing: Threshold={thre_type}, T={T_value}")
            
            # 1. Load Baseline Energy (aveTE_0) DataFrame
            # Assumes this file was generated by organize_energy_results.py
            # Filename: df_aveTE_T{T}_{thr}.csv (Using your standard naming)
            # Note: Your code referenced 'df_aveTE_42_...'. Adjust if needed.
            baseline_file = os.path.join(baseline_csv_dir, f'df_aveTE_T{T_value}_{thre_type}.csv')
            
            if not os.path.exists(baseline_file):
                print(f"  Skipping: Baseline file not found ({baseline_file})")
                continue
                
            source_E_df = pd.read_csv(baseline_file)
            
            delta_ratios_all = []
            
            # 2. Loop through subjects
            for sub_id in id_list:
                # Get Baseline TE for this subject
                try:
                    initial_aveTE = source_E_df[source_E_df['subject_id'] == sub_id]['ave_TE'].values[0]
                except IndexError:
                    print(f"  Warning: Baseline TE not found for subject {sub_id}")
                    # Fill with NaN to maintain alignment
                    delta_ratios_all.append(np.full(n_ROI, np.nan)) 
                    continue
                
                # Get Perturbed Energy Mat path
                mat_path = os.path.join(add1_dir, thre_type, f'{sub_id}_B_add1_OCE_individualSC_T{T_value}_{thre_type}.mat')
                
                # Compute rERC
                rerc_vec = calculate_rerc_for_subject(sub_id, mat_path, initial_aveTE)
                
                if rerc_vec is not None:
                    delta_ratios_all.append(rerc_vec)
                else:
                    delta_ratios_all.append(np.full(n_ROI, np.nan))
            
            # 3. Assemble and Save
            flat_rerc = np.concatenate(delta_ratios_all)
            
            delta_aveTE_df = pd.DataFrame({
                'subject_id': subid_extended,
                'condition': condition_list,
                'state_k': states_list,
                'rERC': flat_rerc # Renamed from 'delta_ratios' for clarity
            })
            
            result_path = os.path.join(output_dir, f'df_rERC_T{T_value}_{thre_type}.csv')
            delta_aveTE_df.to_csv(result_path, index=False)
            print(f"  Saved rERC results to: {result_path}")

if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="Calculate Regional Energy Regulation Capacity (rERC).")
    parser.add_argument("--root_dir", default='../../ukb_raw_data/', help="Root data directory")
    parser.add_argument("--add1_dir", default='../results/energy/B_add1', help="Directory containing B_add1 .mat files")
    parser.add_argument("--baseline_dir", default='../results/df_FoDtAr_TP_E/', help="Directory containing baseline aveTE CSVs")
    parser.add_argument("--output_dir", default='../results/df_FoDtAr_TP_E/', help="Directory to save rERC CSVs")
    
    args = parser.parse_args()
    
    main(args.root_dir, args.add1_dir, args.baseline_dir, args.root_dir, args.output_dir)
